# å„åˆ†æã‚³ãƒ¼ãƒ‰ã‚’çµ±åˆã—ãŸå®Œå…¨ç‰ˆ(ãƒ†ã‚¯ãƒ‹ã‚«ãƒ«åˆ†æï¼‹å€‹åˆ¥æ ªåˆ†æ)
import os
import sqlite3
import pandas as pd
import yfinance as yf
import feedparser
import urllib.parse
import time
import markdown
from flask import Flask, render_template, request, jsonify, send_file
from io import BytesIO
import pdfkit
from datetime import datetime
from dotenv import load_dotenv

# æœ€æ–°ã®Geminiãƒ©ã‚¤ãƒ–ãƒ©ãƒªã‚’ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
from google import genai
from google.genai import types

# .envã‹ã‚‰APIã‚­ãƒ¼(GOOGLE_API_KEY)ã‚’èª­ã¿è¾¼ã¿
load_dotenv()

app = Flask(__name__)

# --- Gemini ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã®åˆæœŸåŒ– (æœ€æ–°SDKæ–¹å¼) ---
client = genai.Client(api_key=os.getenv("GOOGLE_API_KEY"))

# ä½¿ç”¨ã™ã‚‹Geminiãƒ¢ãƒ‡ãƒ«ã®è¨­å®š
MODEL_NAME = "gemini-3-flash-preview"
MODEL_LITE = "gemini-2.5-flash-lite" # ä¼šç¤¾èª¬æ˜ç”¨

# --- ãƒ‘ã‚¹è¨­å®š ---
BASE_DIR = os.path.dirname(os.path.abspath(__file__))
CSV_PATH = os.path.join(BASE_DIR, 'stocks.csv')  # éŠ˜æŸ„ãƒªã‚¹ãƒˆCSV
DB_PATH = os.path.join(BASE_DIR, 'stocks.db')    # æ ªä¾¡ä¿å­˜ç”¨DB

# éŠ˜æŸ„ãƒªã‚¹ãƒˆCSVã‹ã‚‰ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã‚€é–¢æ•°
def load_stock_data():
    if not os.path.exists(CSV_PATH):
        # CSVãŒãªã„å ´åˆã®ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆãƒ‡ãƒ¼ã‚¿
        default_data = [{"ticker": "^N225", "name": "æ—¥çµŒå¹³å‡æ ªä¾¡", "industry": "å…¨ä½“æŒ‡æ•°"}]
        return ["å…¨ä½“æŒ‡æ•°"], default_data
    df = pd.read_csv(CSV_PATH, encoding='utf-8-sig')
    
    # æŒ‡å®šã•ã‚ŒãŸæ¥­ç¨®ã®é †ç•ª
    industry_order = [
        "å…¨ä½“æŒ‡æ•°", "è£½é€ æ¥­(å®Œæˆå“)", "è£½é€ æ¥­(ç´ æ)", "å•†æ¥­ãƒ»ã‚µãƒ¼ãƒ“ã‚¹", 
        "é‡‘èãƒ»æƒ…å ±é€šä¿¡", "åŒ–å­¦ãƒ»åŒ»è–¬å“", "ä¸å‹•ç”£ãƒ»å»ºè¨­", "é‹è¼¸ãƒ»ç‰©æµ", "é£Ÿå“"
    ]
    
    # CSVã«å­˜åœ¨ã™ã‚‹æ¥­ç¨®ã‚’å–å¾—
    existing_industries = df['industry'].unique().tolist()
    
    # æŒ‡å®šé †åºã«åŸºã¥ã„ã¦ã‚½ãƒ¼ãƒˆï¼ˆæŒ‡å®šãƒªã‚¹ãƒˆã«ãªã„ã‚‚ã®ã¯æœ€å¾Œã«è¿½åŠ ï¼‰
    industries = sorted(existing_industries, key=lambda x: industry_order.index(x) if x in industry_order else 999)
    
    stocks = df.to_dict(orient='records')                 # å…¨éŠ˜æŸ„ãƒªã‚¹ãƒˆ
    return industries, stocks

# --- Google News RSS å–å¾—é–¢æ•° ---
def fetch_rss_news(topics, limit=150):
    if not topics:
        return None, "ãƒˆãƒ”ãƒƒã‚¯ãŒé¸æŠã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚", None

    max_total_limit = int(limit)
    news_items = []
    pub_dates = []

    for topic in topics:
        if len(news_items) >= max_total_limit:
            break

        encoded_topic = urllib.parse.quote(topic)
        rss_url = f"https://news.google.com/rss/search?q={encoded_topic}&hl=ja&gl=JP&ceid=JP:ja"
        feed = feedparser.parse(rss_url)

        if not feed.entries:
            continue

        for entry in feed.entries:
            if len(news_items) >= max_total_limit:
                break

            pub_date = None
            if "published_parsed" in entry:
                pub_date = datetime.fromtimestamp(time.mktime(entry.published_parsed))
                pub_dates.append(pub_date)

            summary = entry.summary if "summary" in entry else "(è¦ç´„ãªã—)"
            pub_str = pub_date.strftime("%Y-%m-%d %H:%M") if pub_date else "æ—¥ä»˜æƒ…å ±ãªã—"
            news_items.append(f"ã€{entry.title}ã€‘ ({pub_str})\n{summary}")

    if not news_items:
        return None, "æœ€æ–°ã®ãƒ‹ãƒ¥ãƒ¼ã‚¹ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚", None

    date_range_str = "æ—¥ä»˜æƒ…å ±ãªã—"
    if pub_dates:
        min_date = min(pub_dates).strftime("%Y-%m-%d %H:%M")
        max_date = max(pub_dates).strftime("%Y-%m-%d %H:%M")
        date_range_str = f"{min_date} ~ {max_date}"

    return "\n\n".join(news_items), None, date_range_str

# å–å¾—ã—ãŸæ ªä¾¡ãƒ‡ãƒ¼ã‚¿ã‚’SQLite3ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã«ä¿å­˜ã™ã‚‹é–¢æ•°
def store_to_db(ticker_symbol, df):
    if df.empty: return
    conn = sqlite3.connect(DB_PATH)
    # è¨˜å·ã‚’é™¤å»ã—ã¦ãƒ†ãƒ¼ãƒ–ãƒ«åã‚’ä½œæˆ (ä¾‹: ^N225 -> N225_prices)
    table_name = ticker_symbol.replace("^", "").replace(".", "_") + "_prices"
    df_to_save = df.reset_index()
    df_to_save.to_sql(table_name, conn, if_exists="replace", index=False)
    conn.close()

# ãƒ¡ã‚¤ãƒ³ç”»é¢ã®è¡¨ç¤º
@app.route("/")
def index():
    industries, stocks = load_stock_data()
    return render_template("index.html", industries=industries, stocks=stocks)

# éŠ˜æŸ„ãŒé¸æŠã•ã‚ŒãŸéš›ã«æ ªä¾¡ãƒ‡ãƒ¼ã‚¿ã¨çµ±è¨ˆæƒ…å ±ã‚’å–å¾—ã™ã‚‹API
@app.route("/get_data", methods=["POST"])
def get_data():
    req = request.get_json()
    ticker = req.get("ticker")
    if not ticker: return jsonify({"error": "ticker not provided"}), 400

    # yfinanceã§éå»1å¹´é–“ã®ãƒ‡ãƒ¼ã‚¿ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰
    df = yf.download(ticker, period="1y", interval="1d")
    if df.empty: return jsonify({"error": "no data found"}), 404

    # ãƒãƒ«ãƒã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹å¯¾ç­–
    if isinstance(df.columns, pd.MultiIndex):
        df.columns = df.columns.get_level_values(0)

    # æ¬ æå€¤ï¼ˆç©ºãƒ‡ãƒ¼ã‚¿ï¼‰ã‚’å‰Šé™¤
    df = df.dropna(subset=['Open', 'High', 'Low', 'Close'])

    # --- ğŸ“Š çµ±è¨ˆãƒ‡ãƒ¼ã‚¿ã®è¨ˆç®— ---
    max_price = float(df['High'].max())
    max_date = df['High'].idxmax().strftime("%Y-%m-%d")
    min_price = float(df['Low'].min())
    min_date = df['Low'].idxmin().strftime("%Y-%m-%d")
    # å‡ºæ¥é«˜TOP10ã®æŠ½å‡º
    top10_vol = df.sort_values(by='Volume', ascending=False).head(10)
    volume_ranking = [{"date": idx.strftime("%Y-%m-%d"), "volume": int(row["Volume"])} for idx, row in top10_vol.iterrows()]

    # --- ğŸ¦ ãƒ•ã‚¡ãƒ³ãƒ€ãƒ¡ãƒ³ã‚¿ãƒ«ã‚ºæƒ…å ±ã®å–å¾— ---
    market_cap_str, div_yield_str, payout_ratio_str, ex_div_date_str, roe_str, roa_str, per_str, pbr_str = "N/A", "N/A", "N/A", "N/A", "N/A", "N/A", "N/A", "N/A"
    
    try:
        stock_obj = yf.Ticker(ticker)
        info = stock_obj.info

        # PER/PBRã®å–å¾—
        per = info.get("forwardPE") or info.get("trailingPE")
        if per: per_str = f"{per:.2f}"
        pbr = info.get("priceToBook")
        if pbr: pbr_str = f"{pbr:.2f}"

        # æ™‚ä¾¡ç·é¡ã®å˜ä½èª¿æ•´
        mcap = info.get("marketCap")
        if mcap:
            market_cap_str = f"{mcap / 1e12:.2f} å…†å††" if mcap >= 1e12 else f"{mcap / 1e8:.0f} å„„å††"
        # å„ç¨®æŒ‡æ¨™ã®å–å¾—
        # yfinanceã®dividendYieldã¯éå»å®Ÿç¸¾(Trailing)ã®å ´åˆãŒå¤šãã€æ—¥æœ¬ã®ã‚µã‚¤ãƒˆ(æ ªæ¢ç­‰)ã®äºˆæƒ³åˆ©å›ã‚Šã¨ã‚ºãƒ¬ãŒç”Ÿã˜ã‚‹ãŸã‚
        # dividendRate (ä¼šç¤¾ç™ºè¡¨ã®å¹´é–“é…å½“é¡) ã‚’ç¾åœ¨ã®æ ªä¾¡ã§å‰²ã£ã¦ã€äºˆæƒ³åˆ©å›ã‚Šã«è¿‘ã„å€¤ã‚’ç®—å‡ºã™ã‚‹
        current_price = info.get("currentPrice") or info.get("regularMarketPrice")
        d_rate = info.get("dividendRate") # å¹´é–“é…å½“é¡(äºˆ)
        
        # ç®—å‡ºã‚’è©¦ã¿ã‚‹
        if d_rate and current_price:
            calculated_yield = (d_rate / current_price) * 100
            div_yield_str = f"{calculated_yield:.2f} %"
        else:
            # ç®—å‡ºã§ããªã„å ´åˆã¯ yfinanceæä¾›ã® yield é …ç›®ã‚’ä½¿ç”¨
            dy = info.get("dividendYield") or info.get("trailingAnnualDividendYield")
            if dy:
                # 0.028 -> 2.8% ã®å¤‰æ›ã€‚ç¨€ã«æ—¢ã«2.8ã§å…¥ã£ã¦ã„ã‚‹ã‚±ãƒ¼ã‚¹ãŒã‚ã‚‹ãŸã‚è£œæ­£
                display_dy = dy * 100 if dy < 0.5 else dy 
                div_yield_str = f"{display_dy:.2f} %"
        
        payout = info.get("payoutRatio")
        if payout is not None: payout_ratio_str = f"{payout * 100:.2f} %"
        ex_div = info.get("exDividendDate")
        if ex_div: ex_div_date_str = datetime.fromtimestamp(ex_div).strftime('%m-%d')
        roe = info.get("returnOnEquity")
        if roe: roe_str = f"{roe * 100:.2f} %"
        roa = info.get("returnOnAssets")
        if roa: roa_str = f"{roa * 100:.2f} %"
    except Exception as e:
        print(f"Info fetch error: {e}")
    
    # ãƒ†ã‚¯ãƒ‹ã‚«ãƒ«æŒ‡æ¨™ï¼ˆ5, 25, 75æ—¥ç§»å‹•å¹³å‡ã€25æ—¥ä¹–é›¢ç‡ï¼‰ã®è¨ˆç®—
    df['sma5'] = df['Close'].rolling(5).mean()
    df['sma25'] = df['Close'].rolling(25).mean()
    df['sma75'] = df['Close'].rolling(75).mean()
    df['kairi25'] = (df['Close'] - df['sma25']) / df['sma25'] * 100

    # ãƒ‡ãƒ¼ã‚¿ã‚’DBã«ä¿å­˜
    store_to_db(ticker, df)

    # ãƒ•ãƒ­ãƒ³ãƒˆã‚¨ãƒ³ãƒ‰ï¼ˆJavaScriptï¼‰ã«é€ã‚‹å½¢å¼ã«å¤‰æ›
    def to_list(series):
        return [{"time": idx.strftime("%Y-%m-%d"), "value": float(v)} for idx, v in series.items() if pd.notna(v)]

    return jsonify({
        "candles": [{"time": idx.strftime("%Y-%m-%d"), "open": float(r["Open"]), "high": float(r["High"]), "low": float(r["Low"]), "close": float(r["Close"])} for idx, r in df.iterrows()],
        "sma5": to_list(df['sma5']),
        "sma25": to_list(df['sma25']),
        "sma75": to_list(df['sma75']),
        "kairi25": to_list(df['kairi25']),
        "stats": {
            "max_price": max_price, "max_date": max_date, "min_price": min_price, "min_date": min_date,
            "volume_ranking": volume_ranking, "market_cap": market_cap_str,
            "dividend_yield": div_yield_str, "payout_ratio": payout_ratio_str, "ex_div_date": ex_div_date_str, 
            "roe": roe_str, "roa": roa_str, "per": per_str, "pbr": pbr_str
        }
    })

# --- AI ãƒ†ã‚¯ãƒ‹ã‚«ãƒ«åˆ†æãƒ«ãƒ¼ãƒˆ (ãƒãƒ£ãƒ¼ãƒˆãƒ‡ãƒ¼ã‚¿ã«åŸºã¥ãAIãŒè§£èª¬) ---
@app.route("/analyze", methods=["POST"])
def analyze():
    req = request.get_json()
    ticker = req.get("ticker", "ä¸æ˜")
    # ãƒ‡ãƒ¼ã‚¿ï¼šç›´è¿‘1å¹´é–“ã®æ—¥ä»˜ã¨çµ‚å€¤ã€ä¹–é›¢ç‡ã‚’æŠ½å‡º
    recent_candles = [{"t": c["time"], "c": c["close"]} for c in req.get("candles", [])] 
    recent_kairi = [{"t": k["time"], "v": round(k["value"], 2)} for k in req.get("kairi25", [])]

    prompt = f"""
    # å½¹å‰²
    ã‚ãªãŸã¯é‡‘èå¸‚å ´ã‚’åˆ†æã™ã‚‹ãƒ—ãƒ­ã®æŠ•è³‡ã‚¢ãƒŠãƒªã‚¹ãƒˆã§ã™ã€‚
    
    # ç›®çš„
    æŠ•è³‡åˆ¤æ–­ã®ãŸã‚ã«ã€ä»¥ä¸‹ã®å›³ãƒ‡ãƒ¼ã‚¿ã€å‡ºåŠ›ãƒ«ãƒ¼ãƒ«ã€æŒ‡ç¤ºå†…å®¹ã«å¾“ã£ã¦
    éŠ˜æŸ„ã€Œ{ticker}ã€ã®ãƒ†ã‚¯ãƒ‹ã‚«ãƒ«æŒ‡æ¨™ã«åŸºã¥ãåˆ†æã‚’ã™ã‚‹ã€‚

    # å›³ãƒ‡ãƒ¼ã‚¿
    ç›´è¿‘1å¹´é–“ã®çµ‚å€¤æ¨ç§»: {recent_candles}
    ç›´è¿‘1å¹´é–“ã®25æ—¥ç§»å‹•å¹³å‡ç·šä¹–é›¢ç‡: {recent_kairi}
    
    # å‡ºåŠ›ãƒ«ãƒ¼ãƒ«
    - åˆ†æçµæœã¯Markdownå½¢å¼ã§å‡ºåŠ›ã™ã‚‹ã“ã¨ã€‚
    - åˆ†æçµæœãŒä¸æ˜ç­ãªç®‡æ‰€ã¯ã€ä¸æ˜ç­ãªç®‡æ‰€ã‚’è¨˜è¿°ã—ãŸä¸Šã§ã€ã€Œåˆ¤æ–­ææ–™ä¸è¶³ã€ã¨ã—ã¦ã‚‚ã‚ˆã„ã€‚
    
    # æŒ‡ç¤ºå†…å®¹
    1. ãƒˆãƒ¬ãƒ³ãƒ‰åˆ†æï¼š5æ—¥(çŸ­æœŸ), 25æ—¥(ä¸­æœŸ), 75æ—¥(é•·æœŸ)ã®å„ç§»å‹•å¹³å‡ç·šã®å‘ãã‹ã‚‰ç¾åœ¨ã®ãƒˆãƒ¬ãƒ³ãƒ‰ã‚’åˆ†æã€‚
    2. ç§»å‹•å¹³å‡ç·šåˆ†æï¼š25æ—¥ã¨75æ—¥ã®ã‚¯ãƒ­ã‚¹çŠ¶æ³(ã‚´ãƒ¼ãƒ«ãƒ‡ãƒ³ã‚¯ãƒ­ã‚¹ã¾ãŸã¯ãƒ‡ãƒƒãƒ‰ã‚¯ãƒ­ã‚¹)ã¨ã€ç§»å‹•å¹³å‡ç·š3æœ¬ãŒåæŸã™ã‚‹ã“ã¨ã«ã‚ˆã‚‹ã‚ªãƒ¼ãƒãƒ¼ã‚·ãƒ¥ãƒ¼ãƒˆã®äºˆå…†ã‚’è€ƒå¯Ÿã€‚
    3. ãƒ©ã‚¤ãƒ³åˆ†æï¼šæ˜ç¢ºãªæ”¯æŒç·šãƒ»æŠµæŠ—ç·šãŒè¦‹ãˆã‚‹æ—¥ä»˜ç¯„å›²ã¨ä¾¡æ ¼å¸¯ã‚’åˆ†æã€‚
    4. ä¹–é›¢ç‡è€ƒå¯Ÿï¼šç¾åœ¨ã®25æ—¥ä¹–é›¢ç‡ã¨ã€éå»ã®ä¹–é›¢ç‡ã®æ¨ç§»ã‚’æ¯”è¼ƒã™ã‚‹ã“ã¨ã§ã€å£²ã‚‰ã‚Œã™ããƒ»è²·ã‚ã‚Œã™ãã®ç›®å®‰ã¨ãªã‚‹å€¤ã‚’æ¥µå€¤ã‚’åŸºã«è€ƒå¯Ÿã€‚ç•°å¸¸å€¤ã¨æ€ã‚ã‚Œã‚‹å€¤ã¯ç•°å¸¸å€¤ã§ã‚ã‚‹æ—¨ã‚’è¨˜è¼‰ã™ã‚‹ã“ã¨ã€‚
    5. çµè«–ï¼š1ï½4ã®å†…å®¹ã‚’åŸºã«ã€ä»Šå¾Œã®å±•æœ›ã¨ã€æˆ¦ç•¥ã‚¢ãƒ‰ãƒã‚¤ã‚¹ã‚’å‡ºåŠ›ã€‚
    """
    try:
        response = client.models.generate_content(
            model=MODEL_NAME,
            contents=prompt,
            config=types.GenerateContentConfig(
                thinking_config=types.ThinkingConfig(include_thoughts=True, thinking_level="low"),
            )
        )
        return jsonify({"analysis": response.text})
    except Exception as e:
        return jsonify({"error": str(e)}), 500

# --- AI å€‹åˆ¥æ ªè©³ç´°èª¿æŸ»ãƒ«ãƒ¼ãƒˆ (Googleæ¤œç´¢ã‚’ç”¨ã„ã¦æœ€æ–°ãƒ‹ãƒ¥ãƒ¼ã‚¹ã‚„æ¥­ç¸¾ã‚’åˆ†æ) ---
@app.route("/analyze_full", methods=["POST"])
def analyze_full():
    req = request.get_json()
    ticker = req.get("ticker", "ä¸æ˜")

    prompt = f"""
    # å½¹å‰²
    ã‚ãªãŸã¯é‡‘èå¸‚å ´ã‚’åˆ†æã™ã‚‹ãƒ—ãƒ­ã®æŠ•è³‡ã‚¢ãƒŠãƒªã‚¹ãƒˆã§ã™ã€‚

    # ç›®çš„
    æŠ•è³‡åˆ¤æ–­ã®ãŸã‚ã«ã€ä»¥ä¸‹ã®å‡ºåŠ›ãƒ«ãƒ¼ãƒ«ã¨æŒ‡ç¤ºå†…å®¹ã«å¾“ã£ã¦
    Google Searchã‚’ç”¨ã„ã¦æœ€æ–°æƒ…å ±ã‚’å–å¾—ã™ã‚‹ã“ã¨ã§
    éŠ˜æŸ„ã€Œ{ticker}ã€ã‚’åˆ†æã™ã‚‹ã€‚
    
    # å‡ºåŠ›ãƒ«ãƒ¼ãƒ«
    - åˆ†æçµæœã¯Markdownå½¢å¼ã§å‡ºåŠ›ã™ã‚‹ã“ã¨ã€‚
    - å„é …ç›®ã®æœ€å¾Œã«ã€æ ¹æ‹ ã¨ãªã‚‹å‡ºå…¸URLã‚’å¿…ãšæ˜è¨˜ã™ã‚‹ã“ã¨ã€‚
    - åˆ†æçµæœãŒä¸æ˜ç­ãªç®‡æ‰€ã¯ã€ä¸æ˜ç­ãªç®‡æ‰€ã‚’è¨˜è¿°ã—ãŸä¸Šã§ã€ã€Œåˆ¤æ–­ææ–™ä¸è¶³ã€ã¨ã—ã¦ã‚‚ã‚ˆã„ã€‚
    
    # æŒ‡ç¤ºå†…å®¹
    1. æ¥­ç¸¾æŠ½å‡ºï¼šæœ€æ–°æ±ºç®—ã®å£²ä¸Šãƒ»åˆ©ç›Šã€ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãƒ•ãƒ­ãƒ¼ã€æ¥­ç¸¾å¤‰å‹•è¦å› ã€ãŠã‚ˆã³ä»Šå¾Œã®æ ªä¸»é‚„å…ƒç­–ï¼ˆé…å½“ãƒ»è‡ªç¤¾æ ªè²·ã„ç­‰ï¼‰ã‚’æŠ½å‡ºã€‚
    2. å‹•å‘è€ƒå¯Ÿï¼šç›´è¿‘1å¹´ã®æ ªä¾¡æ¨ç§»ã‚’åˆ†æã—ã€ä¸Šæ˜‡ãƒ»ä¸‹è½ã®ä¸»å› ã‚’è€ƒå¯Ÿã€‚
    3. éœ€çµ¦åˆ†æï¼šç¾åœ¨ã®ä¿¡ç”¨å€ç‡ã¨æ¨ç§»ã‹ã‚‰ã€å€‹äººãƒ»æ©Ÿé–¢ã®å£²è²·å‹•å‘ã‚’åˆ†æã€‚
    4. è©•ä¾¡æŠ½å‡ºï¼šç›®æ¨™æ ªä¾¡ãƒ»ã‚³ãƒ³ã‚»ãƒ³ã‚µã‚¹æƒ…å ±ã‚’æŠ½å‡ºã€‚
    5. çµè«–ï¼šä»Šå¾Œã®æ³¨ç›®ã‚¤ãƒ™ãƒ³ãƒˆã¨ãƒªã‚¹ã‚¯è¦å› ã‚’æ•´ç†ã€‚
    """
    
    try:
        # Googleæ¤œç´¢(Grounding)æ©Ÿèƒ½ã‚’æœ‰åŠ¹åŒ–ã—ã¦å›ç­”ã‚’ç”Ÿæˆ
        response = client.models.generate_content(
            model=MODEL_NAME,
            contents=prompt,
            config=types.GenerateContentConfig(
                tools=[types.Tool(google_search=types.GoogleSearch())],
                thinking_config=types.ThinkingConfig(include_thoughts=True, thinking_level="low"),
            )
        )
        return jsonify({"analysis": response.text})
        
    except Exception as e:
        print(f"Detailed Analysis Error: {str(e)}")
        return jsonify({"error": str(e)}), 500

# --- AI å‡ºæ¥é«˜æ€¥å¢—æ—¥èƒŒæ™¯åˆ†æãƒ«ãƒ¼ãƒˆ (ç‰¹å®šã®æ—¥ã®å‡ºæ¥é«˜æ€¥å¢—è¦å› ã‚’èª¿æŸ») ---
@app.route("/analyze_volume", methods=["POST"])
def analyze_volume():
    req = request.get_json()
    ticker = req.get("ticker", "ä¸æ˜")
    volume_ranking = req.get("volume_ranking", [])

    # æ—¥ä»˜ãŒè¿‘ã„(å‰å¾Œ1æ—¥ä»¥å†…)å‡ºæ¥é«˜æ€¥å¢—æ—¥ã‚’ã‚°ãƒ«ãƒ¼ãƒ—åŒ–
    grouped_dates = []
    if volume_ranking:
        sorted_ranking = sorted(volume_ranking, key=lambda x: x['date'])
        if sorted_ranking:
            current_group = [sorted_ranking[0]['date']]
            for i in range(1, len(sorted_ranking)):
                prev_date = datetime.strptime(sorted_ranking[i-1]['date'], '%Y-%m-%d')
                curr_date = datetime.strptime(sorted_ranking[i]['date'], '%Y-%m-%d')
                if (curr_date - prev_date).days <= 2: # ä¸­1æ—¥(2æ—¥å·®)ã¾ã§ã‚’ã‚°ãƒ«ãƒ¼ãƒ—åŒ–
                    current_group.append(sorted_ranking[i]['date'])
                else:
                    grouped_dates.append(current_group)
                    current_group = [sorted_ranking[i]['date']]
            grouped_dates.append(current_group)

    if not grouped_dates:
        return jsonify({"error": "å‡ºæ¥é«˜æ€¥å¢—æ—¥ã®ãƒ‡ãƒ¼ã‚¿ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚"}), 400

    date_groups_str = "\n".join([f"- {', '.join(group)}" for group in grouped_dates])

    prompt = f"""
    # å½¹å‰²
    ã‚ãªãŸã¯é‡‘èå¸‚å ´ã‚’åˆ†æã™ã‚‹ãƒ—ãƒ­ã®æŠ•è³‡ã‚¢ãƒŠãƒªã‚¹ãƒˆã§ã™ã€‚
    
    # ç›®çš„
    æŠ•è³‡åˆ¤æ–­ã®ãŸã‚ã«ã€ä»¥ä¸‹ã®å‡ºæ¥é«˜ãƒ‡ãƒ¼ã‚¿ã€å‡ºåŠ›ãƒ«ãƒ¼ãƒ«ã€æŒ‡ç¤ºå†…å®¹ã«å¾“ã£ã¦
    éŠ˜æŸ„ã€Œ{ticker}ã€ã®å‡ºæ¥é«˜æ•°1ä½ï½10ä½ã®æ—¥ã«å¸‚å ´ã§ä½•ãŒèµ·ããŸã®ã‹ã‚’ã€
    Google Searchã‚’ç”¨ã„ã¦èª¿æŸ»ã™ã‚‹ã€‚

    # å‡ºæ¥é«˜ãƒ‡ãƒ¼ã‚¿
    {date_groups_str}
    
    # å‡ºåŠ›ãƒ«ãƒ¼ãƒ«
    - åˆ†æçµæœã¯Markdownå½¢å¼ã§å‡ºåŠ›ã™ã‚‹ã“ã¨ã€‚
    - åˆ†æçµæœãŒä¸æ˜ç­ãªç®‡æ‰€ã¯ã€ä¸æ˜ç­ãªç®‡æ‰€ã‚’è¨˜è¿°ã—ãŸä¸Šã§ã€ã€Œåˆ¤æ–­ææ–™ä¸è¶³ã€ã¨ã—ã¦ã‚‚ã‚ˆã„ã€‚
    - èª¿æŸ»å¯¾è±¡ã¯ã€å€‹åˆ¥æ ªãã®ã‚‚ã®ã®èª¿æŸ»ã¨ã€æ—¥çµŒå¹³å‡ãƒ»S&P500ã¨ã„ã£ãŸãƒã‚¯ãƒ­æŒ‡æ¨™ã®èª¿æŸ»ã‚’è¡Œãªã†ã“ã¨ã€‚ãŸã ã—ã€ãƒã‚¯ãƒ­æŒ‡æ¨™ãŒÂ±2%ä»¥ä¸Šå¤‰å‹•ã—ã¦ã„ã‚‹å ´åˆã¯çµŒæ¸ˆçš„ãªãƒ‹ãƒ¥ãƒ¼ã‚¹ã ã‘ã§ãªãã€æ”¿æ²»çš„ãªãƒ‹ãƒ¥ãƒ¼ã‚¹ã‚‚èª¿æŸ»ã™ã‚‹ã“ã¨ã€‚
    - å¯¾è±¡æ—¥ãƒ»ç™ºç”Ÿã‚¤ãƒ™ãƒ³ãƒˆãƒ»æŠ•è³‡å®¶å¿ƒç†ã®éƒ¨åˆ†ã¯ã€è¡¨å½¢å¼ã§ã¾ã¨ã‚ã‚‹ã“ã¨ã€‚
    - å„é …ç›®ã®æœ€å¾Œã«ã€æ ¹æ‹ ã¨ãªã‚‹å‡ºå…¸URLã‚’æœ€å¾Œã«æ˜è¨˜ã™ã‚‹ã“ã¨ã€‚
    - å€‹åˆ¥æ ªã«ã‚ˆã‚‹è¦å› ã¯å€‹åˆ¥è¦å› ã¨ã—ã€ãƒã‚¯ãƒ­æŒ‡æ¨™ã«ã‚ˆã‚‹è¦å› ã¯å¸‚æ³è¦å› ã¨ã™ã‚‹ã“ã¨ã§ã€åˆ†ã‘ã¦è¨˜è¿°ã™ã‚‹ã“ã¨ã€‚ã¾ãŸã€ã©ã¡ã‚‰ã®è¦å› ã‚‚å½±éŸ¿ãŒå¤§ãã„å ´åˆã¯å…±é€šè¦å› ã¨ã—ã¦ä¸€ç·’ã«è¨˜è¿°ã™ã‚‹ã“ã¨ã€‚
    
    # æŒ‡ç¤ºå†…å®¹
    1. ç™ºç”Ÿã‚¤ãƒ™ãƒ³ãƒˆï¼šæ±ºç®—ç™ºè¡¨ã€ãƒã‚¯ãƒ­æŒ‡æ¨™ã€çµŒæ¸ˆãƒ‹ãƒ¥ãƒ¼ã‚¹ãªã©ã€åŸå› ã¨ãªã£ãŸäº‹è±¡ã‚’èª¿æŸ»ã€‚
    2. æŠ•è³‡å®¶å¿ƒç†ï¼šå¸‚å ´ãŒãã®ãƒ‹ãƒ¥ãƒ¼ã‚¹ã‚’ã©ã†å—ã‘æ­¢ã‚ã€ãªãœå‡ºæ¥é«˜ãŒæ€¥å¢—ã—ãŸã‹ã‚’è€ƒå¯Ÿã€‚
    3. æ¨ªæ–­çš„è€ƒå¯Ÿï¼šè¤‡æ•°ã®æ—¥ä»˜ãŒã‚ã‚‹å ´åˆã€ãã‚Œã‚‰ãŒã€Œä¸‹è½ã¨åç™ºã€ãªã©ã©ã®ã‚ˆã†ãªä¸€é€£ã®ã‚¹ãƒˆãƒ¼ãƒªãƒ¼ã‚’å½¢æˆã—ã¦ã„ã‚‹ã‹ã‚’è€ƒå¯Ÿã€‚
    """
    
    try:
        response = client.models.generate_content(
            model=MODEL_NAME,
            contents=prompt,
            config=types.GenerateContentConfig(
                tools=[types.Tool(google_search=types.GoogleSearch())],
                thinking_config=types.ThinkingConfig(include_thoughts=True, thinking_level="low"),
            )
        )
        return jsonify({"analysis": response.text})
        
    except Exception as e:
        print(f"Volume Analysis Error: {str(e)}")
        return jsonify({"error": str(e)}), 500

# --- å¸‚æ³åˆ†æãƒ«ãƒ¼ãƒˆ (RSSãƒ‹ãƒ¥ãƒ¼ã‚¹ã«åŸºã¥ãAIãŒè§£èª¬) ---
@app.route("/analyze_market", methods=["POST"])
def analyze_market():
    req = request.get_json()
    selected_topics = req.get("topics", [])
    free_keyword = req.get("free_keyword", "")
    
    # ã‚ªãƒ—ã‚·ãƒ§ãƒ³è¨­å®š
    beginner_mode = req.get("beginner_mode", False)
    deep_analysis = req.get("deep_analysis", False)
    technical_mode = req.get("technical_mode", False)
    short_term = req.get("short_term", False)
    mid_term = req.get("mid_term", False)
    sector_view = req.get("sector_view", False)

    query_parts = selected_topics[:]
    if free_keyword:
        query_parts.append(free_keyword)

    if not query_parts:
        return jsonify({"error": "åˆ†æå¯¾è±¡ã®ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‚’é¸æŠã¾ãŸã¯å…¥åŠ›ã—ã¦ãã ã•ã„ã€‚"}), 400

    # ãƒ‹ãƒ¥ãƒ¼ã‚¹å–å¾—
    news_text, error, date_range = fetch_rss_news(query_parts, 150)
    if error:
        return jsonify({"error": error}), 404

    # Geminiã¸ã®æŒ‡ç¤ºä½œæˆ
    extra_instructions = ""
    if beginner_mode:
        extra_instructions += "\n- åˆå­¦è€…å‘ã‘èª¬æ˜ï¼šèª¬æ˜ã®éš›ã«ä½¿ç”¨ã™ã‚‹å°‚é–€ç”¨èªã«ã€Œâ€»ã€ã§æ³¨é‡ˆã‚’è¿½åŠ ã—ã¦æŠ•è³‡åˆå­¦è€…ã§ã‚‚åˆ†ã‹ã‚Šã‚„ã™ã„èª¬æ˜ã‚’ã™ã‚‹ã“ã¨ã€‚"
    if deep_analysis:
        extra_instructions += "\n- è©³ç´°åˆ†æï¼šå¸‚å ´ãŒæŠ±ãˆã‚‹ãƒªã‚¹ã‚¯ã¨ãã®å½±éŸ¿ã«ã¤ã„ã¦åˆ†æã™ã‚‹ã“ã¨ã€‚å¸‚å ´å¿ƒç†ã¨ãƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£ã«ã¤ã„ã¦ã‚‚åˆ†æã™ã‚‹ã“ã¨ã€‚"
    if technical_mode:
        extra_instructions += "\n- ãƒ†ã‚¯ãƒ‹ã‚«ãƒ«åˆ†æï¼šãƒˆãƒ¬ãƒ³ãƒ‰(ä¸Šæ˜‡ã¾ãŸã¯ä¸‹é™)ã€æ”¯æŒãƒ»æŠµæŠ—ã€å‡ºæ¥é«˜ã«ã¤ã„ã¦åˆ†æã—ã¦ãã ã•ã„ã€‚"     
    if short_term:
        extra_instructions += "\n- çŸ­æœŸåˆ†æï¼šç›´è¿‘1é€±é–“ã®çŸ­æœŸçš„ãªç›®ç·šã®åˆ†æã‚’ã™ã‚‹ã“ã¨ã€‚ç‰¹ã«ã€ä¿¡ç”¨å–å¼•ã®çŠ¶æ³ã«ã¤ã„ã¦åˆ†æã™ã‚‹ã“ã¨ã€‚"   
    if mid_term:
        extra_instructions += "\n- ä¸­æœŸåˆ†æï¼šç›´è¿‘1ãƒ¶æœˆã®ä¸­æœŸçš„ãªç›®ç·šã®åˆ†æã‚’ã™ã‚‹ã“ã¨ã€‚ç‰¹ã«ã€æœˆé–“ã®ä¸»è¦ãªçµŒæ¸ˆæŒ‡æ¨™ã‚„ãƒˆãƒ¬ãƒ³ãƒ‰ã®å¤‰åŒ–ã«ã¤ã„ã¦åˆ†æã™ã‚‹ã“ã¨ã€‚"   
    if sector_view:
        extra_instructions += "\n- æ¥­ç¨®åˆ¥åˆ†æï¼šãƒ‹ãƒ¥ãƒ¼ã‚¹ä¸Šã§è©±é¡Œã«ãªã£ã¦ã„ã‚‹å„æ¥­ç¨®ã®çŠ¶æ³ã«ã¤ã„ã¦åˆ†æã™ã‚‹ã“ã¨ã€‚"

    prompt = f"""
    # å½¹å‰²
    ã‚ãªãŸã¯é‡‘èå¸‚å ´ã‚’åˆ†æã™ã‚‹ãƒ—ãƒ­ã®æŠ•è³‡ã‚¢ãƒŠãƒªã‚¹ãƒˆã§ã™ã€‚
    
    # ç›®çš„
    æŠ•è³‡åˆ¤æ–­ã®ãŸã‚ã«ã€ä»¥ä¸‹ã®ãƒ‹ãƒ¥ãƒ¼ã‚¹ãƒ‡ãƒ¼ã‚¿ã€å‡ºåŠ›ãƒ«ãƒ¼ãƒ«ã€æŒ‡ç¤ºå†…å®¹ã«å¾“ã£ã¦
    å–å¾—ãƒ‹ãƒ¥ãƒ¼ã‚¹ã«åŸºã¥ãå¸‚å ´ã®åˆ†æã‚’ã™ã‚‹ã€‚
    
    # ãƒ‹ãƒ¥ãƒ¼ã‚¹ãƒ‡ãƒ¼ã‚¿
    ãƒ‹ãƒ¥ãƒ¼ã‚¹æ•°ã¨æœŸé–“ï¼š{date_range}
    ãƒ‹ãƒ¥ãƒ¼ã‚¹æœ¬æ–‡ï¼š{news_text}
    
    # å‡ºåŠ›ãƒ«ãƒ¼ãƒ«
    - åˆ†æçµæœã¯Markdownå½¢å¼ã§å‡ºåŠ›ã™ã‚‹ã“ã¨ã€‚
    - åˆ†æçµæœãŒä¸æ˜ç­ãªç®‡æ‰€ã¯ã€ä¸æ˜ç­ãªç®‡æ‰€ã‚’è¨˜è¿°ã—ãŸä¸Šã§ã€ã€Œåˆ¤æ–­ææ–™ä¸è¶³ã€ã¨ã—ã¦ã‚‚ã‚ˆã„ã€‚
    - å‡ºåŠ›çµæœã®å†’é ­ã«ã€ãƒ‹ãƒ¥ãƒ¼ã‚¹æ•°ã¨æœŸé–“ã‚’è¨˜è¼‰ã™ã‚‹ã“ã¨ã€‚
    - ä»Šå¾Œã®äºˆæ¸¬ã¯è¡Œã‚ãªãã¦ã‚‚ã‚ˆã„ã€‚
    
    # æŒ‡ç¤ºå†…å®¹
    - åˆ†é¡æŠ½å‡ºï¼šãƒˆãƒ”ãƒƒã‚¯ã”ã¨ã«è¦‹å‡ºã—ã‚’åˆ†ã‘ã€é–¢é€£ã™ã‚‹ãƒ‹ãƒ¥ãƒ¼ã‚¹ã®è¦ç‚¹ã‚’æŠ½å‡ºã€‚
    - å½±éŸ¿è€ƒå¯Ÿï¼šå„ãƒˆãƒ”ãƒƒã‚¯ãŒå¸‚å ´ã¸ä¸ãˆã‚‹å½±éŸ¿ã‚’è€ƒå¯Ÿã€‚
    
    ## è¿½åŠ ã®æŒ‡ç¤ºå†…å®¹
    {extra_instructions}
    """

    try:
        response = client.models.generate_content(
            model=MODEL_NAME,
            contents=prompt,
            config=types.GenerateContentConfig(
                thinking_config=types.ThinkingConfig(include_thoughts=True, thinking_level="high"),
            )
        )
        return jsonify({
            "analysis": response.text,
            "date_range": date_range
        })
    except Exception as e:
        return jsonify({"error": str(e)}), 500

# --- ç·åˆåˆ†æãƒ«ãƒ¼ãƒˆ (è“„ç©ã•ã‚ŒãŸè¤‡æ•°ã®åˆ†æçµæœã‚’çµ±åˆ) ---
@app.route("/analyze_total", methods=["POST"])
def analyze_total():
    req = request.get_json()
    selected_results = req.get("selected_results", [])
    
    if not selected_results:
        return jsonify({"error": "åˆ†æå¯¾è±¡ã®çµæœãŒé¸æŠã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚"}), 400

    # éå»ã®åˆ†æçµæœã‚’çµåˆ
    combined_texts = []
    for res in selected_results:
        text = f"ã€{res['title']}ã€‘\n{res['content']}"
        combined_texts.append(text)
    
    context_text = "\n\n---\n\n".join(combined_texts)

    prompt = f"""
    # å½¹å‰²
    ã‚ãªãŸã¯é‡‘èå¸‚å ´ã®ãƒ¬ãƒãƒ¼ãƒˆã‚’åˆ†æã™ã‚‹ãƒ—ãƒ­ã®æŠ•è³‡æˆ¦ç•¥å®¶ã§ã™ã€‚

    # ç›®çš„
    æœ€çµ‚çš„ãªæŠ•è³‡åˆ¤æ–­ã‚’ã™ã‚‹ãŸã‚ã«ã€ä»¥ä¸‹ã®ãƒ¬ãƒãƒ¼ãƒˆãƒ‡ãƒ¼ã‚¿ã€å‡ºåŠ›ãƒ«ãƒ¼ãƒ«ã€æŒ‡ç¤ºå†…å®¹ã«å¾“ã£ã¦
    å„åˆ†æçµæœã‹ã‚‰å¾—ã‚‰ã‚ŒãŸæƒ…å ±ã‚’æ•´ç†ãƒ»åˆ†æã™ã‚‹ã€‚
    
    # ãƒ¬ãƒãƒ¼ãƒˆãƒ‡ãƒ¼ã‚¿
    {context_text}

    # å‡ºåŠ›ãƒ«ãƒ¼ãƒ«
    - åˆ†æçµæœã¯Markdownå½¢å¼ã§å‡ºåŠ›ã™ã‚‹ã“ã¨ã€‚
    - åˆ†æçµæœãŒä¸æ˜ç­ãªç®‡æ‰€ã¯ã€ä¸æ˜ç­ãªç®‡æ‰€ã‚’è¨˜è¿°ã—ãŸä¸Šã§ã€ã€Œåˆ¤æ–­ææ–™ä¸è¶³ã€ã¨ã—ã¦ã‚‚ã‚ˆã„ã€‚
    
    # æŒ‡ç¤ºå†…å®¹
    1. å„åˆ†æçµæœã®è¦ç‚¹ã‚’çµ±åˆã—ã€ç¾åœ¨ã®å¸‚å ´ç’°å¢ƒã«ãŠã‘ã‚‹ãƒªã‚¹ã‚¯ã¨ãƒãƒ£ãƒ³ã‚¹ã‚’æ•´ç†ã€‚
    2. ãƒ‡ãƒ¼ã‚¿ã®ä¸­ã«åŒã˜æ¥­ç¨®ã®ç•°ãªã‚‹éŠ˜æŸ„ãŒå«ã¾ã‚Œã¦ã„ã‚‹å ´åˆã¯éŠ˜æŸ„æ¯”è¼ƒã‚’ã—ã¦ã‚‚ã‚ˆã„ã€‚ä¾‹ãˆã°ã€ç›¸å¯¾çš„ãªå¼·ã¿ã¨å¼±ã¿ã€æ¥­ç¸¾æ¨ç§»ã€æ ªä¸»é‚„å…ƒå§¿å‹¢ã®é•ã„ç­‰ã‚’è§£èª¬ã€‚
    3. çŸ­æœŸçš„(1ã‚«æœˆä»¥å†…)ãƒ»ä¸­æœŸçš„(1ã‚«æœˆï½3ã‚«æœˆä»¥å†…)ãƒ»é•·æœŸçš„(3ã‚«æœˆï½1å¹´ä»¥å†…)ãªè¦–ç‚¹ã§ã€ç·åˆçš„ãªæŠ•è³‡æˆ¦ç•¥åŠã³ã€ãã®æˆ¦ç•¥ã®æ ¹æ‹ ã‚’æä¾›ã€‚
    4. æœ€çµ‚çš„ãªæŠ•è³‡åˆ¤æ–­ææ–™ã¨ã—ã¦ã®ç·æ‹¬ã¨ã€ã¨ã—ã¦ã®ã‚¢ãƒ‰ãƒã‚¤ã‚¹ã‚’ã€ãã®é‡‘èå•†å“ã‚’ä¿æœ‰ã—ã¦ã„ã‚‹äººå‘ã‘ã€ä¿æœ‰ã—ã¦ã„ãªã„äººå‘ã‘ãã‚Œãã‚Œã«æä¾›ã€‚
    """

    try:
        response = client.models.generate_content(
            model=MODEL_NAME,
            contents=prompt,
            config=types.GenerateContentConfig(
                thinking_config=types.ThinkingConfig(include_thoughts=True, thinking_level="high"),
            )
        )
        return jsonify({"analysis": response.text})
    except Exception as e:
        return jsonify({"error": str(e)}), 500

# --- AI ä¼šç¤¾èª¬æ˜å–å¾—ãƒ«ãƒ¼ãƒˆ (Google Searchã‚’æ´»ç”¨) ---
@app.route("/get_company_info", methods=["POST"])
def get_company_info():
    req = request.get_json()
    ticker = req.get("ticker", "ä¸æ˜")
    name = req.get("name", "ä¸æ˜")
    
    # ç¾åœ¨ã®æ ªä¾¡ç­‰ã®è£œåŠ©ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—ã—ã¦AIã«æ¸¡ã™
    price_info = ""
    try:
        stock_obj = yf.Ticker(ticker)
        # infoã‹ã‚‰æœ€æ–°ä¾¡æ ¼ã‚’å–å¾—ï¼ˆcurrentPrice ã¾ãŸã¯ regularMarketPriceï¼‰
        current_price = stock_obj.info.get("currentPrice") or stock_obj.info.get("regularMarketPrice")
        if current_price:
            currency = stock_obj.info.get("currency", "JPY")
            price_info = f"ç¾åœ¨ã®æ ªä¾¡: {current_price} {currency}"
    except Exception as e:
        print(f"Price fetch error in company info: {e}")

    prompt = f"""
    # å½¹å‰²
    ã‚ãªãŸã¯ç‰¹å®šã®ä¼æ¥­ã®æƒ…å ±ã‚’èª¿æŸ»ã™ã‚‹ã“ã¨ã‚’å¾—æ„ã¨ã™ã‚‹ä¼æ¥­ã‚¢ãƒŠãƒªã‚¹ãƒˆã§ã™ã€‚
    
    # ç›®çš„
    ç°¡æ½”ãªä¼æ¥­æƒ…å ±ã‚’çŸ¥ã‚‹ãŸã‚ã«ã€
    ä»¥ä¸‹ã®å‡ºåŠ›ãƒ«ãƒ¼ãƒ«ã¨æŒ‡ç¤ºå†…å®¹ã«å¾“ã£ã¦
    æ—¥æœ¬æ ªéŠ˜æŸ„ã€Œ{name} ({ticker})ã€ã«ã¤ã„ã¦ã€
    Google Searchã‚’ç”¨ã„ã¦æœ€æ–°æƒ…å ±ã‚’èª¿æŸ»ã™ã‚‹ã€‚
    
    # å‡ºåŠ›ãƒ«ãƒ¼ãƒ«
    - å›ç­”ã¯Markdownå½¢å¼ã§å‡ºåŠ›ã™ã‚‹ã“ã¨ã€‚
    - å„é …ç›®ã®ã‚¿ã‚¤ãƒˆãƒ«ã®å¾Œã«æ”¹è¡Œã™ã‚‹ã“ã¨ã€‚
    - å„é …ç›®1ã€œ4è¡Œç¨‹åº¦ã§ç°¡æ½”ã«ã¾ã¨ã‚ã‚‹ã“ã¨ã€‚
    - å‡ºåŠ›çµæœã®æœ€å¾Œã®éƒ¨åˆ†ã«ã€ã€Œä¼šç¤¾URL:ã€ã¨ã—ã¦ã€ä¼šç¤¾ã®å…¬å¼ã‚µã‚¤ãƒˆURLã‚’å¿…ãšè¨˜è¼‰ã™ã‚‹ã“ã¨ã€‚
    - åˆ†æçµæœãŒä¸æ˜ç­ãªç®‡æ‰€ã¯ã€ä¸æ˜ç­ãªç®‡æ‰€ã‚’è¨˜è¿°ã—ãŸä¸Šã§ã€ã€Œåˆ¤æ–­ææ–™ä¸è¶³ã€ã¨ã—ã¦ã‚‚ã‚ˆã„ã€‚
    
    # æŒ‡ç¤ºå†…å®¹
    1. äº‹æ¥­å†…å®¹ã¨å„ªä½æ€§: ä¸»è¦ãªäº‹æ¥­ã‚’è¨˜è¿°ã—ã€ãã®å¾Œã«ç›´è¿‘1å¹´ã®ä¸­ã§åŠ›ã‚’å…¥ã‚Œã¦ã„ã‚‹äº‹æ¥­ã‚’è¨˜è¿°ã€‚ãã®å¾Œã«ã€ç«¶åˆä»–ç¤¾ã«å¯¾ã™ã‚‹å„ªä½æ€§ã‚’è¨˜è¿°ã€‚
    2. æ´»å‹•æ‹ ç‚¹: å£²ä¸Šé«˜æ§‹æˆæ¯”ç‡ã®å¤§ãã•ã®è¦³ç‚¹ã‹ã‚‰ã€å£²ä¸Šé«˜ã®é †ã«å›½å†…ã¾ãŸã¯æµ·å¤–ã®æ‹ ç‚¹è¨˜è¿°ã€‚
    3. é…å½“å®Ÿç¸¾ã¨å„ªå¾…: éå»10å¹´é–“ã®é…å½“å®Ÿç¸¾ã‚’èª¿æŸ»ã—ã¦å–å¾—ã—ã¦é…å½“å®Ÿç¸¾ã®æ¨ç§»(å¢—åŠ ãƒ»æ¸›å°‘ãƒ»æ¨ªã°ã„ç­‰)ã‚’è©•ä¾¡ã€‚åŠ ãˆã¦ã€ç¾åœ¨ã‹ã‚‰ä¸€å¹´å‰ã¾ã§ã®æœŸé–“ã§ã€æ ªä¸»å„ªå¾…åˆ¶åº¦ã®å®Ÿæ–½çŠ¶æ³ãƒ»å„ªå¾…ã®å†…å®¹ã‚’è¨˜è¿°ã€‚
    """
    
    try:
        response = client.models.generate_content(
            model=MODEL_LITE,
            contents=prompt,
            config=types.GenerateContentConfig(
                tools=[types.Tool(google_search=types.GoogleSearch())]
            )
        )
        return jsonify({"info": response.text})
    except Exception as e:
        print(f"Company Info Error: {str(e)}")
        return jsonify({"error": str(e)}), 500

# --- PDFå‡ºåŠ›ãƒ«ãƒ¼ãƒˆ (pdfkitä½¿ç”¨) ---
@app.route("/export_pdf", methods=["POST"])
def export_pdf():
    try:
        req = request.get_json()
        title = req.get("title", "åˆ†æãƒ¬ãƒãƒ¼ãƒˆ")
        content_md = req.get("content", "")
        ticker = req.get("ticker", "")

        # Markdownã‚’HTMLã«å¤‰æ›
        content_html = markdown.markdown(content_md, extensions=['tables', 'fenced_code'])

        # PDFç”¨ã®HTMLãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆ
        # ãƒ¡ã‚¤ãƒªã‚ªãªã©ã®Windowsæ¨™æº–ãƒ•ã‚©ãƒ³ãƒˆã‚’æŒ‡å®š
        full_html = f"""
        <html>
        <head>
            <meta charset="UTF-8">
            <style>
                body {{ font-family: "Meiryo", "MS Gothic", sans-serif; line-height: 1.6; color: #333; margin: 2cm; }}
                h1 {{ color: #1a237e; border-bottom: 2px solid #1a237e; padding-bottom: 10px; }}
                h2 {{ color: #0d47a1; border-left: 5px solid #0d47a1; padding-left: 10px; margin-top: 20px; }}
                h3 {{ color: #1565c0; }}
                table {{ width: 100%; border-collapse: collapse; margin: 20px 0; }}
                th, td {{ border: 1px solid #ddd; padding: 8px; text-align: left; }}
                th {{ background-color: #f2f2f2; }}
                .header {{ text-align: right; font-size: 0.9em; color: #666; margin-bottom: 20px; }}
                .footer {{ text-align: center; font-size: 0.8em; color: #999; margin-top: 30px; }}
            </style>
        </head>
        <body>
            <div class="header">ç™ºè¡Œæ—¥: {datetime.now().strftime('%Y-%m-%d %H:%M')}</div>
            <h1>{title} {'(' + ticker + ')' if ticker else ''}</h1>
            <div class="content">
                {content_html}
            </div>
            <div class="footer">Generated by æ—¥çµŒ225ã‚¹ãƒãƒ¼ãƒˆAIåˆ†æ</div>
        </body>
        </html>
        """

        # wkhtmltopdfã®ãƒ‘ã‚¹è¨­å®š
        # ä¸€èˆ¬çš„ãªã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«å…ˆã‚’æ¢ç´¢
        path_wkhtmltopdf = r'C:\Program Files\wkhtmltopdf\bin\wkhtmltopdf.exe'
        if not os.path.exists(path_wkhtmltopdf):
            # ã‚«ãƒ¬ãƒ³ãƒˆãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã«ã‚ã‚‹å ´åˆ (ãƒãƒ¼ã‚¿ãƒ–ãƒ«ç‰ˆãªã©)
            path_wkhtmltopdf = os.path.join(BASE_DIR, 'wkhtmltopdf.exe')
        
        config = None
        if os.path.exists(path_wkhtmltopdf):
            config = pdfkit.configuration(wkhtmltopdf=path_wkhtmltopdf)
        
        # ã‚ªãƒ—ã‚·ãƒ§ãƒ³è¨­å®š
        options = {
            'encoding': "UTF-8",
            'enable-local-file-access': None,
            'quiet': '',
            'no-outline': None
        }
        
        # PDFç”Ÿæˆ
        try:
            pdf_bytes = pdfkit.from_string(full_html, False, options=options, configuration=config)
        except OSError as e:
            if "No wkhtmltopdf executable found" in str(e):
                return jsonify({"error": "ã‚µãƒ¼ãƒãƒ¼ã« wkhtmltopdf ãŒã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚å…¬å¼ã‚µã‚¤ãƒˆã‹ã‚‰ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã™ã‚‹ã‹ã€wkhtmltopdf.exeã‚’é…ç½®ã—ã¦ãã ã•ã„ã€‚"}), 500
            raise e

        pdf_io = BytesIO(pdf_bytes)
        filename = f"{title}_{datetime.now().strftime('%Y%m%d%H%M%S')}.pdf"
        
        return send_file(
            pdf_io,
            mimetype='application/pdf',
            as_attachment=True,
            download_name=filename
        )
    except Exception as e:
        print(f"PDF Export Error: {e}")
        return jsonify({"error": str(e)}), 500

if __name__ == "__main__":
    # é–‹ç™ºç”¨ã‚µãƒ¼ãƒãƒ¼ã®èµ·å‹•
    app.run(host="0.0.0.0", port=5000, debug=True)
